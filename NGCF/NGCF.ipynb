{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "405bb047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.4\n",
      "  latest version: 4.10.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/graphranko_madan\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.6\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge\n",
      "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-1_gnu\n",
      "  ca-certificates    conda-forge/linux-64::ca-certificates-2021.10.8-ha878542_0\n",
      "  certifi            conda-forge/linux-64::certifi-2016.9.26-py36_0\n",
      "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.36.1-hea4e1c9_2\n",
      "  libffi             conda-forge/linux-64::libffi-3.4.2-h9c3ff4c_4\n",
      "  libgcc-ng          conda-forge/linux-64::libgcc-ng-11.2.0-h1d223b6_11\n",
      "  libgomp            conda-forge/linux-64::libgomp-11.2.0-h1d223b6_11\n",
      "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-11.2.0-he4da1e4_11\n",
      "  libzlib            conda-forge/linux-64::libzlib-1.2.11-h36c2ea0_1013\n",
      "  ncurses            conda-forge/linux-64::ncurses-6.2-h58526e2_4\n",
      "  openssl            conda-forge/linux-64::openssl-1.1.1l-h7f98852_0\n",
      "  pip                conda-forge/noarch::pip-21.3.1-pyhd8ed1ab_0\n",
      "  python             conda-forge/linux-64::python-3.6.13-hb7a2778_2_cpython\n",
      "  python_abi         conda-forge/linux-64::python_abi-3.6-2_cp36m\n",
      "  readline           conda-forge/linux-64::readline-8.1-h46c0cb4_0\n",
      "  setuptools         conda-forge/linux-64::setuptools-49.6.0-py36h5fab9bb_3\n",
      "  sqlite             conda-forge/linux-64::sqlite-3.36.0-h9cd32fc_2\n",
      "  tk                 conda-forge/linux-64::tk-8.6.11-h27826a3_1\n",
      "  wheel              conda-forge/noarch::wheel-0.37.0-pyhd8ed1ab_1\n",
      "  xz                 conda-forge/linux-64::xz-5.2.5-h516909a_1\n",
      "  zlib               conda-forge/linux-64::zlib-1.2.11-h36c2ea0_1013\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate graphranko_madan\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !conda create -y --name graphranko_madan python=3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2220ddd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no change     /home/ec2-user/anaconda3/condabin/conda\n",
      "no change     /home/ec2-user/anaconda3/bin/conda\n",
      "no change     /home/ec2-user/anaconda3/bin/conda-env\n",
      "no change     /home/ec2-user/anaconda3/bin/activate\n",
      "no change     /home/ec2-user/anaconda3/bin/deactivate\n",
      "no change     /home/ec2-user/anaconda3/etc/profile.d/conda.sh\n",
      "no change     /home/ec2-user/anaconda3/etc/fish/conf.d/conda.fish\n",
      "no change     /home/ec2-user/anaconda3/shell/condabin/Conda.psm1\n",
      "no change     /home/ec2-user/anaconda3/shell/condabin/conda-hook.ps1\n",
      "no change     /home/ec2-user/anaconda3/lib/python3.7/site-packages/xontrib/conda.xsh\n",
      "no change     /home/ec2-user/anaconda3/etc/profile.d/conda.csh\n",
      "no change     /home/ec2-user/.bashrc\n",
      "No action taken.\n"
     ]
    }
   ],
   "source": [
    "!conda init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "295dc264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\r\n",
      "To initialize your shell, run\r\n",
      "\r\n",
      "    $ conda init <SHELL_NAME>\r\n",
      "\r\n",
      "Currently supported shells are:\r\n",
      "  - bash\r\n",
      "  - fish\r\n",
      "  - tcsh\r\n",
      "  - xonsh\r\n",
      "  - zsh\r\n",
      "  - powershell\r\n",
      "\r\n",
      "See 'conda init --help' for more information and options.\r\n",
      "\r\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda activate graphranko_madan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b4f61c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/graphranko_madan\n",
      "\n",
      "  added / updated specs:\n",
      "    - tensorflow=1.8.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    absl-py-0.15.0             |     pyhd8ed1ab_0          98 KB  conda-forge\n",
      "    astor-0.8.1                |     pyh9f0ad1d_0          25 KB  conda-forge\n",
      "    bleach-1.5.0               |           py36_0          23 KB  conda-forge\n",
      "    c-ares-1.18.1              |       h7f98852_0         113 KB  conda-forge\n",
      "    dataclasses-0.8            |     pyh787bdff_2          22 KB  conda-forge\n",
      "    gast-0.5.0                 |     pyhd8ed1ab_0          12 KB  conda-forge\n",
      "    grpcio-1.38.1              |   py36h8e87921_0         2.2 MB  conda-forge\n",
      "    html5lib-0.9999999         |           py36_0         181 KB  conda-forge\n",
      "    libprotobuf-3.18.0         |       h780b84a_1         2.6 MB  conda-forge\n",
      "    markdown-3.3.4             |     pyhd8ed1ab_0          67 KB  conda-forge\n",
      "    protobuf-3.18.0            |   py36hc4f0c31_0         344 KB  conda-forge\n",
      "    tensorboard-1.8.0          |           py36_1         3.1 MB  conda-forge\n",
      "    tensorflow-1.8.0           |           py36_1        42.1 MB  conda-forge\n",
      "    termcolor-1.1.0            |             py_2           6 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        50.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  absl-py            conda-forge/noarch::absl-py-0.15.0-pyhd8ed1ab_0\n",
      "  astor              conda-forge/noarch::astor-0.8.1-pyh9f0ad1d_0\n",
      "  bleach             conda-forge/linux-64::bleach-1.5.0-py36_0\n",
      "  c-ares             conda-forge/linux-64::c-ares-1.18.1-h7f98852_0\n",
      "  dataclasses        conda-forge/noarch::dataclasses-0.8-pyh787bdff_2\n",
      "  gast               conda-forge/noarch::gast-0.5.0-pyhd8ed1ab_0\n",
      "  grpcio             conda-forge/linux-64::grpcio-1.38.1-py36h8e87921_0\n",
      "  html5lib           conda-forge/linux-64::html5lib-0.9999999-py36_0\n",
      "  importlib-metadata conda-forge/linux-64::importlib-metadata-4.8.1-py36h5fab9bb_0\n",
      "  libblas            conda-forge/linux-64::libblas-3.9.0-12_linux64_openblas\n",
      "  libcblas           conda-forge/linux-64::libcblas-3.9.0-12_linux64_openblas\n",
      "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-11.2.0-h69a702a_11\n",
      "  libgfortran5       conda-forge/linux-64::libgfortran5-11.2.0-h5c6108e_11\n",
      "  liblapack          conda-forge/linux-64::liblapack-3.9.0-12_linux64_openblas\n",
      "  libopenblas        conda-forge/linux-64::libopenblas-0.3.18-pthreads_h8fe5266_0\n",
      "  libprotobuf        conda-forge/linux-64::libprotobuf-3.18.0-h780b84a_1\n",
      "  markdown           conda-forge/noarch::markdown-3.3.4-pyhd8ed1ab_0\n",
      "  numpy              conda-forge/linux-64::numpy-1.19.5-py36hfc0c790_2\n",
      "  protobuf           conda-forge/linux-64::protobuf-3.18.0-py36hc4f0c31_0\n",
      "  six                conda-forge/noarch::six-1.16.0-pyh6c4a22f_0\n",
      "  tensorboard        conda-forge/linux-64::tensorboard-1.8.0-py36_1\n",
      "  tensorflow         conda-forge/linux-64::tensorflow-1.8.0-py36_1\n",
      "  termcolor          conda-forge/noarch::termcolor-1.1.0-py_2\n",
      "  typing_extensions  conda-forge/noarch::typing_extensions-3.10.0.2-pyha770c72_0\n",
      "  webencodings       conda-forge/noarch::webencodings-0.5.1-py_1\n",
      "  werkzeug           conda-forge/noarch::werkzeug-2.0.1-pyhd8ed1ab_0\n",
      "  zipp               conda-forge/noarch::zipp-3.6.0-pyhd8ed1ab_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi                                  2016.9.26-py36_0 --> 2021.5.30-py36h5fab9bb_0\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# conda install --force-reinstall -y -q --name graphranko_madan tensorflow=1.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbb0dde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/graphranko_madan\n",
      "\n",
      "  added / updated specs:\n",
      "    - scikit-learn=0.19\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    scikit-learn-0.19.2        |py36_blas_openblasha84fab4_201        12.7 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        12.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  scikit-learn       conda-forge/linux-64::scikit-learn-0.19.2-py36_blas_openblasha84fab4_201\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87a21d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/graphranko_madan\n",
      "\n",
      "  added / updated specs:\n",
      "    - numpy=1.14.3\n",
      "\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/graphranko_madan\n",
      "\n",
      "  added / updated specs:\n",
      "    - scipy=1.1.0\n",
      "\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - sklearn=0.19.1\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/conda-forge/linux-64\n",
      "  - https://conda.anaconda.org/conda-forge/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! /home/ec2-user/anaconda3/condabin/conda install --force-reinstall -y -q --name graphranko_madan numpy=1.14.3\n",
    "! /home/ec2-user/anaconda3/condabin/conda install --force-reinstall -y -q --name graphranko_madan scipy=1.1.0\n",
    "! /home/ec2-user/anaconda3/condabin/conda install --force-reinstall -y -q --name graphranko_madan scikit-learn=0.19.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7997a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ec2-user/SageMaker/graphranko\")\n",
    "sys.path.append(\"/home/ec2-user/SageMaker/graphranko/NGCF\")\n",
    "sys.path.append(\"/home/ec2-user/SageMaker/graphranko/NGCF/utility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad66d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fef5c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\r\n",
      "To initialize your shell, run\r\n",
      "\r\n",
      "    $ conda init <SHELL_NAME>\r\n",
      "\r\n",
      "Currently supported shells are:\r\n",
      "  - bash\r\n",
      "  - fish\r\n",
      "  - tcsh\r\n",
      "  - xonsh\r\n",
      "  - zsh\r\n",
      "  - powershell\r\n",
      "\r\n",
      "See 'conda init --help' for more information and options.\r\n",
      "\r\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda activate graphranko_madan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f9f2591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n",
      "1.14.3\n",
      "0.19.1\n",
      "0.22.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "print(sc.__version__)\n",
    "print(sk.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb2c198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users=52643, n_items=91599\n",
      "n_interactions=2984108\n",
      "n_train=2380730, n_test=603378, sparsity=0.00062\n"
     ]
    }
   ],
   "source": [
    "%tb \n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "from utility.helper import *\n",
    "from utility.batch_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0cd08c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility.parser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bc2107d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users=29858, n_items=40981\n",
      "n_interactions=1027370\n",
      "n_train=810128, n_test=217242, sparsity=0.00084\n",
      "already load adj matrix (70839, 70839) 0.27478837966918945\n",
      "use the normalized adjacency matrix\n",
      "using xavier initialization\n",
      "without pretraining.\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# ! python NGCF.py --dataset gowalla --regs [1e-5] --embed_size 64 --layer_size [64,64,64] --lr 0.0001 --save_flag 1 --pretrain 0 --batch_size 1024 --epoch 400 --verbose 1 --node_dropout [0.1] --mess_dropout [0.1,0.1,0.1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "803e779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already load adj matrix (144242, 144242) 0.7545373439788818\n",
      "use the normalized adjacency matrix\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
    "\n",
    "config = dict()\n",
    "config['n_users'] = data_generator.n_users\n",
    "config['n_items'] = data_generator.n_items\n",
    "\n",
    "\"\"\"\n",
    "*********************************************************\n",
    "Generate the Laplacian matrix, where each entry defines the decay factor (e.g., p_ui) between two connected nodes.\n",
    "\"\"\"\n",
    "plain_adj, norm_adj, mean_adj = data_generator.get_adj_mat()\n",
    "\n",
    "if args.adj_type == 'plain':\n",
    "    config['norm_adj'] = plain_adj\n",
    "    print('use the plain adjacency matrix')\n",
    "\n",
    "elif args.adj_type == 'norm':\n",
    "    config['norm_adj'] = norm_adj\n",
    "    print('use the normalized adjacency matrix')\n",
    "\n",
    "elif args.adj_type == 'gcmc':\n",
    "    config['norm_adj'] = mean_adj\n",
    "    print('use the gcmc adjacency matrix')\n",
    "\n",
    "else:\n",
    "    config['norm_adj'] = mean_adj + sp.eye(mean_adj.shape[0])\n",
    "    print('use the mean adjacency matrix')\n",
    "    \n",
    "    \n",
    "t0 = time()\n",
    "\n",
    "if args.pretrain == -1:\n",
    "    pretrain_data = load_pretrained_data()\n",
    "else:\n",
    "    pretrain_data = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c42a84b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144242, 144242)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d62731c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NGCF import NGCF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5face721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using xavier initialization\n"
     ]
    }
   ],
   "source": [
    "model = NGCF(data_config=config, pretrain_data=pretrain_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47714046",
   "metadata": {},
   "source": [
    "*********************************************************\n",
    "Save the model parameters.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70aa172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if args.save_flag == 1:\n",
    "    layer = '-'.join([str(l) for l in eval(args.layer_size)])\n",
    "    weights_save_path = '%sweights/%s/%s/%s/l%s_r%s' % (args.weights_path, args.dataset, model.model_type, layer,\n",
    "                                                        str(args.lr), '-'.join([str(r) for r in eval(args.regs)]))\n",
    "    ensureDir(weights_save_path)\n",
    "    save_saver = tf.train.Saver(max_to_keep=1)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789ec387",
   "metadata": {},
   "source": [
    "   \n",
    "*********************************************************\n",
    "#### Reload the pretrained model parameters.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ba93efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without pretraining.\n"
     ]
    }
   ],
   "source": [
    "if args.pretrain == 1:\n",
    "    layer = '-'.join([str(l) for l in eval(args.layer_size)])\n",
    "\n",
    "    pretrain_path = '%sweights/%s/%s/%s/l%s_r%s' % (args.weights_path, args.dataset, model.model_type, layer,\n",
    "                                                    str(args.lr), '-'.join([str(r) for r in eval(args.regs)]))\n",
    "\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname(pretrain_path + '/checkpoint'))\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print('load the pretrained model parameters from: ', pretrain_path)\n",
    "\n",
    "        # *********************************************************\n",
    "        # get the performance from pretrained model.\n",
    "        if args.report != 1:\n",
    "            users_to_test = list(data_generator.test_set.keys())\n",
    "            ret = test(sess, model, users_to_test, drop_flag=True)\n",
    "            cur_best_pre_0 = ret['recall'][0]\n",
    "\n",
    "            pretrain_ret = 'pretrained model recall=[%.5f, %.5f], precision=[%.5f, %.5f], hit=[%.5f, %.5f],' \\\n",
    "                           'ndcg=[%.5f, %.5f]' % \\\n",
    "                           (ret['recall'][0], ret['recall'][-1],\n",
    "                            ret['precision'][0], ret['precision'][-1],\n",
    "                            ret['hit_ratio'][0], ret['hit_ratio'][-1],\n",
    "                            ret['ndcg'][0], ret['ndcg'][-1])\n",
    "            print(pretrain_ret)\n",
    "    else:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        cur_best_pre_0 = 0.\n",
    "        print('without pretraining.')\n",
    "\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    cur_best_pre_0 = 0.\n",
    "    print('without pretraining.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b8e2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.mess_dropout = '[0.1]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "198a5ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# *********************************************************\n",
    "# Get the performance w.r.t. different sparsity levels.\n",
    "# \"\"\"\n",
    "if args.report == 1:\n",
    "    assert args.test_flag == 'full'\n",
    "    users_to_test_list, split_state = data_generator.get_sparsity_split()\n",
    "    users_to_test_list.append(list(data_generator.test_set.keys()))\n",
    "    split_state.append('all')\n",
    "\n",
    "    report_path = '%sreport/%s/%s.result' % (args.proj_path, args.dataset, model.model_type)\n",
    "    ensureDir(report_path)\n",
    "    f = open(report_path, 'w')\n",
    "    f.write(\n",
    "        'embed_size=%d, lr=%.4f, layer_size=%s, keep_prob=%s, regs=%s, loss_type=%s, adj_type=%s\\n'\n",
    "        % (args.embed_size, args.lr, args.layer_size, args.keep_prob, args.regs, args.loss_type, args.adj_type))\n",
    "\n",
    "    for i, users_to_test in enumerate(users_to_test_list):\n",
    "        ret = test(sess, model, users_to_test, drop_flag=True)\n",
    "\n",
    "        final_perf = \"recall=[%s], precision=[%s], hit=[%s], ndcg=[%s]\" % \\\n",
    "                     ('\\t'.join(['%.5f' % r for r in ret['recall']]),\n",
    "                      '\\t'.join(['%.5f' % r for r in ret['precision']]),\n",
    "                      '\\t'.join(['%.5f' % r for r in ret['hit_ratio']]),\n",
    "                      '\\t'.join(['%.5f' % r for r in ret['ndcg']]))\n",
    "        print(final_perf)\n",
    "\n",
    "        f.write('\\t%s\\n\\t%s\\n' % (split_state[i], final_perf))\n",
    "    f.close()\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcedffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# *********************************************************\n",
    "# Train.\n",
    "# \"\"\"\n",
    "loss_loger, pre_loger, rec_loger, ndcg_loger, hit_loger = [], [], [], [], []\n",
    "stopping_step = 0\n",
    "should_stop = False\n",
    "\n",
    "args.epoch = 1\n",
    "\n",
    "t1 = time()\n",
    "loss, mf_loss, emb_loss, reg_loss = 0., 0., 0., 0.\n",
    "n_batch = data_generator.n_train // args.batch_size + 1\n",
    "\n",
    "\n",
    "\n",
    "# if np.isnan(loss) == True:\n",
    "#     print('ERROR: loss is nan.')\n",
    "#     sys.exit()\n",
    "\n",
    "# # # print the test evaluation metrics each 10 epochs; pos:neg = 1:10.\n",
    "# # if (epoch + 1) % 10 != 0:\n",
    "# #     if args.verbose > 0 and epoch % args.verbose == 0:\n",
    "# #         perf_str = 'Epoch %d [%.1fs]: train==[%.5f=%.5f + %.5f]' % (\n",
    "# #             epoch, time() - t1, loss, mf_loss, reg_loss)\n",
    "# #         print(perf_str)\n",
    "# #     continue\n",
    "\n",
    "# t2 = time()\n",
    "# users_to_test = list(data_generator.test_set.keys())\n",
    "# ret = test(sess, model, users_to_test, drop_flag=True)\n",
    "\n",
    "# t3 = time()\n",
    "\n",
    "# loss_loger.append(loss)\n",
    "# rec_loger.append(ret['recall'])\n",
    "# pre_loger.append(ret['precision'])\n",
    "# ndcg_loger.append(ret['ndcg'])\n",
    "# hit_loger.append(ret['hit_ratio'])\n",
    "\n",
    "# if args.verbose > 0:\n",
    "#     perf_str = 'Epoch %d [%.1fs + %.1fs]: train==[%.5f=%.5f + %.5f + %.5f], recall=[%.5f, %.5f], ' \\\n",
    "#                'precision=[%.5f, %.5f], hit=[%.5f, %.5f], ndcg=[%.5f, %.5f]' % \\\n",
    "#                (epoch, t2 - t1, t3 - t2, loss, mf_loss, emb_loss, reg_loss, ret['recall'][0], ret['recall'][-1],\n",
    "#                 ret['precision'][0], ret['precision'][-1], ret['hit_ratio'][0], ret['hit_ratio'][-1],\n",
    "#                 ret['ndcg'][0], ret['ndcg'][-1])\n",
    "#     print(perf_str)\n",
    "\n",
    "# cur_best_pre_0, stopping_step, should_stop = early_stopping(ret['recall'][0], cur_best_pre_0,\n",
    "#                                                             stopping_step, expected_order='acc', flag_step=5)\n",
    "\n",
    "# # *********************************************************\n",
    "# # early stopping when cur_best_pre_0 is decreasing for ten successive steps.\n",
    "# # if should_stop == True:\n",
    "# #     break\n",
    "\n",
    "# # *********************************************************\n",
    "# # save the user & item embeddings for pretraining.\n",
    "# if ret['recall'][0] == cur_best_pre_0 and args.save_flag == 1:\n",
    "#     save_saver.save(sess, weights_save_path + '/weights', global_step=epoch)\n",
    "#     print('save the weights in path: ', weights_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab6bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(n_batch):\n",
    "    users, pos_items, neg_items = data_generator.sample()\n",
    "    _, batch_loss, batch_mf_loss, batch_emb_loss, batch_reg_loss = sess.run([model.opt, model.loss, model.mf_loss, model.emb_loss, model.reg_loss],\n",
    "                       feed_dict={model.users: users, model.pos_items: pos_items,\n",
    "                                  model.node_dropout: eval(args.node_dropout),\n",
    "                                  model.mess_dropout: eval(args.mess_dropout),\n",
    "                                  model.neg_items: neg_items})\n",
    "    loss += batch_loss\n",
    "    mf_loss += batch_mf_loss\n",
    "    emb_loss += batch_emb_loss\n",
    "    reg_loss += batch_reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34174427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2325"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4454f941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
