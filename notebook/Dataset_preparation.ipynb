{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books.csv                   \u001b[34mbackup\u001b[m\u001b[m\r\n",
      "Dataset Preprocessing.ipynb meta_Electronics.json\r\n",
      "Electronics.csv             meta_Electronics.json.gz\r\n",
      "Electronics.json.gz         ratings_Electronics.csv\r\n",
      "HinSage_Model.ipnb          \u001b[34mrec-amz-Books\u001b[m\u001b[m\r\n",
      "HinSage_Model.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import stellargraph as sg\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.data import EdgeSplitter\n",
    "from stellargraph.mapper import GraphSAGELinkGenerator\n",
    "from stellargraph.layer import GraphSAGE, link_classification\n",
    "from stellargraph.data import UniformRandomWalk\n",
    "from stellargraph.data import UnsupervisedSampler\n",
    "from stellargraph import globalvar\n",
    "from stellargraph import datasets\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.data import EdgeSplitter\n",
    "from stellargraph.mapper import GraphSAGELinkGenerator\n",
    "from stellargraph.mapper import HinSAGELinkGenerator\n",
    "from stellargraph.layer import GraphSAGE, link_classification, HinSAGE\n",
    "from stellargraph.data import UniformRandomWalk\n",
    "from stellargraph.data import UnsupervisedSampler\n",
    "from stellargraph import globalvar\n",
    "from stellargraph import datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing, feature_extraction, model_selection\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Rating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-12482a4436c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrating_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Electronics.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rating_dataset = pd.read_csv(\"Electronics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset.columns = [\"item\", \"user\", \"rating\", \"timestamp\"]\n",
    "rating_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(rating_dataset.item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(rating_dataset.user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset['rating'].plot.hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rating_dataset[['user', 'item']].groupby(['user'])['item'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.hist(bins=[10, 20, 30, 50, 100, 200, 300, 400, 500, 600], log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = rating_dataset[['user', 'item']].groupby(['item'])['user'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.hist(bins=20, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the meta data\n",
    "\n",
    "metadata = []\n",
    "with gzip.open('meta_Electronics.json.gz') as f:\n",
    "    for l in f:\n",
    "        metadata.append(json.loads(l.strip()))\n",
    "    \n",
    "# total length of list, this number equals total number of products\n",
    "print(len(metadata))\n",
    "\n",
    "# first row of the list\n",
    "print(metadata[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Reading Review Dataset\n",
    "#! wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/Electronics.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_item_meta = {meta['asin']: meta for meta in metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_item_meta['0060009810']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset.dropna(inplace = True)\n",
    "print(rating_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_item_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove item that does not exist in metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_with_metadata = set(rating_dataset.item).intersection(set(dict_item_meta.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset = rating_dataset[rating_dataset.item.isin(items_with_metadata)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"edges, users, items ={} {} {}\".format(rating_dataset.shape[0], len(set(rating_dataset.item)), len(set(rating_dataset.user))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_item = rating_dataset.loc[rating_dataset.rating >= 3]\n",
    "edges = df_user_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"edges, users, items ={} {} {}\".format(df_user_item.shape[0], len(set(df_user_item.item)), len(set(df_user_item.user))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df_user_item.item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_user_item.groupby(['user'])['item'].count() >= 20\n",
    "users = list(x[x == True].index)\n",
    "print(len(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Keep users having more than 20 item\n",
    "df_user_item = df_user_item.loc[df_user_item['user'].isin(users)]\n",
    "print(\"edges, items, users ={} {} {}\".format(df_user_item.shape[0], len(set(df_user_item.item)), len(set(df_user_item.user))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reduce users\n",
    "users = users[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Keep users having more than 20 item\n",
    "df_user_item = df_user_item.loc[df_user_item['user'].isin(users)]\n",
    "df_user_item.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"edges, items, users ={} {} {}\".format(df_user_item.shape[0], len(set(df_user_item.item)), len(set(df_user_item.user))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge = df_user_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce all rating file for these subset of users and items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_dataset_for_users = rating_dataset.loc[rating_dataset['user'].isin(set(df_user_item.user))]\n",
    "df_rating_dataset_for_user_items = df_rating_dataset_for_users.loc[df_rating_dataset_for_users['item'].isin(set(df_user_item.item))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"edges, items, users ={} {} {}\".format(df_rating_dataset_for_user_items.shape[0], len(set(df_rating_dataset_for_user_items.item)), len(set(df_rating_dataset_for_user_items.user))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rating_dataset_for_user_items[[\"item\", \"user\", \"rating\"]].to_csv(\"/Users/msinghal/SourceCodes/Personal/LightGCN/Data/amazon-electronics-v3/user-item-rating.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating integer id for users and items to reduce memory footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_map = {}\n",
    "item_id_map = {}\n",
    "users = list(set(df_user_item.user))\n",
    "items = list(set(df_user_item.item))\n",
    "user_id_map = {users[index]:index for index in range(0, len(users))}\n",
    "item_id_map = {items[index]:index for index in range(0, len(items))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_item['user_id'] = df_user_item['user'].apply(lambda x:user_id_map[x])\n",
    "df_user_item['item_id'] = df_user_item['item'].apply(lambda x:item_id_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df_user_item, test_size=0.32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train edges {}\".format(train_df.shape))\n",
    "print(\"test edges {}\".format(test_df.shape))\n",
    "print(\"users in training data  {}\".format(len(set(train_df.user))))\n",
    "print(\"users in test data {}\".format(len(set(test_df.user))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"items in training data  {}\".format(len(set(train_df.item))))\n",
    "print(\"items in test data {}\".format(len(set(test_df.item))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining metadata with edge rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create users, items and training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_user_item_list = pd.DataFrame(columns = ['user', 'items'])\n",
    "# for i in set(df_user_item['user']):\n",
    "#     items = \" \".join(list(df_user_item.loc[df_user_item['user'] == i]['item']))\n",
    "#     df_user_item_list = df_user_item_list.append({'user':i, 'items':items}, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_item_list_train = pd.DataFrame(columns = ['user', 'items'])\n",
    "for i in set(train_df['user']):\n",
    "    items = \" \".join(list(train_df.loc[train_df['user'] == i]['item']))\n",
    "    df_user_item_list_train = df_user_item_list_train.append({'user':i, 'items':items}, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_item_list_test = pd.DataFrame(columns = ['user', 'items'])\n",
    "for i in set(test_df['user']):\n",
    "    items = \" \".join(list(test_df.loc[test_df['user'] == i]['item']))\n",
    "    df_user_item_list_test = df_user_item_list_test.append({'user':i, 'items':items}, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_item_list_train['user_id'] = df_user_item_list_train['user'].apply(lambda x:user_id_map[x])\n",
    "df_user_item_list_train['item_ids'] = df_user_item_list_train['items'].apply(lambda x:\" \".join([str(item_id_map[item]) for item in x.split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_item_list_test['user_id'] = df_user_item_list_test['user'].apply(lambda x:user_id_map[x])\n",
    "df_user_item_list_test['item_ids'] = df_user_item_list_test['items'].apply(lambda x:\" \".join([str(item_id_map[item]) for item in x.split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_item_list_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_item_list_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/Users/msinghal/SourceCodes/Personal/LightGCN/Data/amazon-electronics-v3/train.txt\", 'w') as f:\n",
    "#     lines = [str(row['user_id']) + \" \" + row['item_ids'] for index, row in df_user_item_list_train.iterrows()]\n",
    "#     f.writelines(\"\\n\".join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/Users/msinghal/SourceCodes/Personal/LightGCN/Data/amazon-electronics-v3/test.txt\", 'w') as f:\n",
    "#     lines = [str(row['user_id']) + \" \" + row['item_ids'] for index, row in df_user_item_list_test.iterrows()]\n",
    "#     f.writelines(\"\\n\".join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/Users/msinghal/SourceCodes/Personal/LightGCN/Data/amazon-electronics-v3/user_list.txt\", 'w') as f:\n",
    "#     lines = [str(user) + \" \" + str(user_id) for user, user_id in user_id_map.items()]\n",
    "#     f.writelines(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = set()\n",
    "for item, item_id in item_id_map.items():\n",
    "    categories = categories | set(dict_item_meta[item]['category'])\n",
    "categories = list(set(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(set(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_item_meta[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/Users/msinghal/SourceCodes/Personal/LightGCN/Data/amazon-electronics-v3/categories.txt\", 'w') as f:\n",
    "#     lines = []\n",
    "#     for i in range(0, len(categories)):\n",
    "#         lines.append(str(i) + \"|\" + categories[i])\n",
    "#     f.writelines(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/Users/msinghal/SourceCodes/Personal/LightGCN/Data/amazon-electronics-v3/item_meta_list.txt\", 'w') as f:\n",
    "#     lines = []\n",
    "#     for item, item_id in item_id_map.items():\n",
    "#         x = str(item) + \" \" + str(item_id)  \n",
    "#         y = \"\"\n",
    "#         for category in categories:\n",
    "#             y = y + \" \" + '1' if category in dict_item_meta[item]['category'] else y + \" \" + '0'\n",
    "#         lines.append(x + y)\n",
    "#     f.writelines(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############### Done ########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Analaysis and Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### graphsage model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(set(df_user_item['user']) | set(df_user_item['item']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_features = [[0 for i in range(0, len(keys))] for j in range(0, len(keys))]\n",
    "for i in range(0,len(keys)):\n",
    "    nodes_features[i][i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "def generate_nx_graph_port_as_node_features(rating_dataset, node_features):\n",
    "    G = nx.Graph()\n",
    "    # Add nodes\n",
    "    for i in range (0, len(keys)):\n",
    "        feature = node_features[i]\n",
    "        if keys[i] in users:\n",
    "            G.add_node(keys[i], feature=feature, label=\"u\")\n",
    "        else:\n",
    "            G.add_node(keys[i], feature=feature, label=\"i\")\n",
    "    for index, row in rating_dataset.iterrows():\n",
    "        src_node_id = row['user']\n",
    "        dst_node_id = row['item']\n",
    "        G.add_edge(src_node_id, dst_node_id, rating=row['rating'])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = generate_nx_graph_port_as_node_features(df_user_item, nodes_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph import StellarGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = StellarGraph.from_networkx(g, node_features=\"feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphsage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = G.nodes()\n",
    "gsWalks = 20\n",
    "gsWalkLength = 20\n",
    "batch_size = 50\n",
    "epochs = 1\n",
    "num_samples = [5, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_samples = UnsupervisedSampler(\n",
    "    G, nodes=nodes, length=gsWalkLength, number_of_walks=gsWalks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??UnsupervisedSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes = G.nodes()\n",
    "# gsWalks = 10\n",
    "# gsWalkLength = 5\n",
    "# batch_size = 20\n",
    "# epochs = 1\n",
    "# num_samples = [20,20]\n",
    "# layer_sizes = [50,50]\n",
    "\n",
    "# unsupervised_samples = UnsupervisedSampler(\n",
    "#     G, nodes=nodes, length=gsWalkLength, number_of_walks=gsWalks\n",
    "# )\n",
    "# generator = HinSAGELinkGenerator(G, batch_size, num_samples, head_node_types=('u','i'))\n",
    "# train_gen = generator.flow(unsupervised_samples)\n",
    "# graphsage = HinSAGE(\n",
    "#     layer_sizes=layer_sizes, generator=generator, bias=True, dropout=0.0, normalize=\"l2\"\n",
    "# )\n",
    "# x_inp, x_out = graphsage.in_out_tensors()\n",
    "# prediction = link_classification(\n",
    "#     output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"ip\"\n",
    "# )(x_out)\n",
    "# model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "# model.compile(\n",
    "#     optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "#     loss=keras.losses.binary_crossentropy,\n",
    "#     metrics=[keras.metrics.binary_accuracy],\n",
    "# )\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_gen,\n",
    "#     epochs=epochs,\n",
    "#     verbose=1,\n",
    "#     use_multiprocessing=False,\n",
    "#     workers=4,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.mapper import GraphSAGENodeGenerator, HinSAGENodeGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??GraphSAGENodeGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(G, nodes):\n",
    "    x_inp_src = x_inp[0::2]\n",
    "    x_out_src = x_out[0]\n",
    "    embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)\n",
    "    node_ids = nodes\n",
    "    #node_gen = HinSAGENodeGenerator(G, batch_size, num_samples).flow(node_ids)\n",
    "\n",
    "    node_embeddings = model.predict(test_gen, workers=4, verbose=1)\n",
    "    \n",
    "    return node_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embeddings = get_embeddings(G, G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_node_embeddings = pd.DataFrame(data=new_embeddings, index=nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latest_similarity_matrix = create_similarity_matrix(latest_node_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latest_similarity_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latest_similarity_matrix.loc[users, users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HinSage  on Amazon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, feature_extraction, model_selection\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph.mapper import HinSAGELinkGenerator\n",
    "from stellargraph.layer import HinSAGE, link_regression\n",
    "from tensorflow.keras import Model, optimizers, losses, metrics\n",
    "\n",
    "import multiprocessing\n",
    "from stellargraph import datasets\n",
    "from stellargraph import StellarGraph\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Amz_Dataset():\n",
    "    def load(self, metadata=False):\n",
    "        \"\"\"\n",
    "        Load this dataset into an undirected heterogeneous graph, downloading it if required.\n",
    "\n",
    "        The graph has two types of nodes (``user`` and ``movie``) and one type of edge (``rating``).\n",
    "\n",
    "        The dataset includes some node features on both users and movies: on users, they consist of\n",
    "        categorical features (``gender`` and ``job``) which are one-hot encoded into binary\n",
    "        features, and an ``age`` feature that is scaled to have mean = 0 and standard deviation = 1.\n",
    "\n",
    "        Returns:\n",
    "            A tuple where the first element is a :class:`.StellarGraph` instance containing the graph\n",
    "            data and features, and the second element is a pandas DataFrame of edges, with columns\n",
    "            ``user_id``, ``movie_id`` and ``rating`` (a label from 1 to 5).\n",
    "        \"\"\"\n",
    "        rating_file = \"/Users/msinghal/SourceCodes/Personal/LightGCN/Data/amazon-electronics-v2/user-item-rating.csv\"\n",
    "        user_file = \"/Users/msinghal/SourceCodes/Personal/LightGCN/Data/amazon-electronics-v2/user_list.txt\"\n",
    "        item_file = \"/Users/msinghal/SourceCodes/Personal/LightGCN/Data/amazon-electronics-v2/item_meta_list.txt\"\n",
    "        category_file = \"/Users/msinghal/SourceCodes/Personal/LightGCN/Data/amazon-electronics-v2/categories.txt\"\n",
    "\n",
    "        edges = pd.read_csv(rating_file)\n",
    "\n",
    "        users = pd.read_csv(\n",
    "            user_file,\n",
    "            sep=\" \",\n",
    "            header=None,\n",
    "            names=[\"user\", \"user_id\"]\n",
    "        )\n",
    "\n",
    "        categories = pd.read_csv(\n",
    "            category_file,\n",
    "            sep=\"|\",\n",
    "            header=None,\n",
    "            names=[\"category_id\", \"category\"]\n",
    "        )\n",
    "\n",
    "        items = pd.read_csv(\n",
    "            item_file,\n",
    "            sep=\" \",\n",
    "            header=None,\n",
    "            names=[\"item\", \"item_id\"] + list(categories[\"category\"])\n",
    "        )\n",
    "\n",
    "        # manage the IDs\n",
    "        def u(users):\n",
    "            return \"u_\" + users.astype(str)\n",
    "\n",
    "        def m(movies):\n",
    "            return \"i_\" + movies.astype(str)\n",
    "\n",
    "        edges = edges.merge(users, on=\"user\").merge(items, on=\"item\")[[\"user_id\", \"item_id\", \"rating\"]]\n",
    "\n",
    "        users[\"user_id\"] = u(users[\"user_id\"])\n",
    "        users.set_index(\"user_id\", inplace=True)\n",
    "\n",
    "        #\n",
    "        items[\"item_id\"] = m(items[\"item_id\"])\n",
    "        items.set_index(\"item_id\", inplace=True)\n",
    "        items.drop(\"item\", inplace=True, axis=1)\n",
    "        #\n",
    "        edges[\"user_id\"] = u(edges[\"user_id\"])\n",
    "        edges[\"item_id\"] = m(edges[\"item_id\"])\n",
    "\n",
    "        # convert categorical user features to numeric, and normalize age\n",
    "        # feature_encoding = preprocessing.OneHotEncoder(sparse=False)\n",
    "        # onehot = feature_encoding.fit_transform(users[[\"user\"]])\n",
    "        # scaled_age = preprocessing.scale(users[\"age\"])\n",
    "        values = np.zeros((len(users.index), len(users.index)))\n",
    "        np.fill_diagonal(values, 1)\n",
    "        encoded_users = pd.DataFrame(values, index=users.index, columns=users.index)\n",
    "        if not metadata:\n",
    "            values = np.zeros((len(items.index), len(items.index)))\n",
    "            np.fill_diagonal(values, 1)\n",
    "            encoded_items = pd.DataFrame(values, index=items.index, columns=items.index)\n",
    "            return self.generate_nx_graph_with_features(edges, encoded_users, encoded_items), edges\n",
    "        return self.generate_nx_graph_with_features(edges, encoded_users, items), edges\n",
    "\n",
    "    def generate_nx_graph_with_features(self, edges, users, items):\n",
    "        G = nx.Graph()\n",
    "        # Add nodes\n",
    "        for user_id in users.index:\n",
    "            G.add_node(user_id, feature=users.loc[user_id, :], label=\"user\")\n",
    "        for item_id in items.index:\n",
    "            G.add_node(item_id, feature=items.loc[item_id, :], label=\"item\")\n",
    "\n",
    "        for index, row in edges.iterrows():\n",
    "            src_node_id = row['user_id']\n",
    "            dst_node_id = row['item_id']\n",
    "            G.add_edge(src_node_id, dst_node_id, rating=row['rating'])\n",
    "        return StellarGraph.from_networkx(G, node_features=\"feature\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Amz_Dataset()\n",
    "G, edges_with_ratings = dataset.load(metadata=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_with_ratings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "edges_train, edges_test = model_selection.train_test_split(\n",
    "    edges_with_ratings, train_size=0.7, test_size=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist_train = list(edges_train[[\"user_id\", \"item_id\"]].itertuples(index=False))\n",
    "edgelist_test = list(edges_test[[\"user_id\", \"item_id\"]].itertuples(index=False))\n",
    "\n",
    "labels_train = edges_train[\"rating\"]\n",
    "labels_test = edges_test[\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edges_train.shape)\n",
    "print(edges_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = [8, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = HinSAGELinkGenerator(\n",
    "    G, batch_size, num_samples, head_node_types=[\"user\", \"item\"]\n",
    ")\n",
    "train_gen = generator.flow(edgelist_train, labels_train, shuffle=True)\n",
    "test_gen = generator.flow(edgelist_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.schema.type_adjacency_list(generator.head_node_types, len(num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.schema.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinsage_layer_sizes = [32, 32]\n",
    "assert len(hinsage_layer_sizes) == len(num_samples)\n",
    "\n",
    "hinsage = HinSAGE(\n",
    "    layer_sizes=hinsage_layer_sizes, generator=generator, bias=True, dropout=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expose input and output sockets of hinsage:\n",
    "x_inp, x_out = hinsage.in_out_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final estimator layer\n",
    "score_prediction = link_regression(edge_embedding_method=\"concat\")(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "def root_mean_square_error(s_true, s_pred):\n",
    "    return K.sqrt(K.mean(K.pow(s_true - s_pred, 2)))\n",
    "\n",
    "\n",
    "model = Model(inputs=x_inp, outputs=score_prediction)\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(lr=1e-2),\n",
    "    loss=losses.mean_squared_error,\n",
    "    metrics=[root_mean_square_error, metrics.mae],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the number of workers to use for model training\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = HinSAGELinkGenerator(\n",
    "    G, batch_size, num_samples, head_node_types=[\"user\", \"item\"]\n",
    ")\n",
    "train_gen = generator.flow(edgelist_train, labels_train, shuffle=True)\n",
    "test_gen = generator.flow(edgelist_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.mapper import GraphSAGENodeGenerator, HinSAGENodeGenerator\n",
    "def get_embeddings(G, nodes):\n",
    "    x_inp_src = x_inp[0::2]\n",
    "    x_out_src = x_out[0]\n",
    "    embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)\n",
    "    node_ids = nodes\n",
    "    #egd = HinSAGENodeGenerator(G, batch_size, num_samples, head_node_types=[\"user\", \"item\"]).flow(node_ids)\n",
    "\n",
    "    node_embeddings = model.predict(test_gen, workers=4, verbose=1)\n",
    "    \n",
    "    return node_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embeddings = get_embeddings(G, G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = model.evaluate(\n",
    "    test_gen, verbose=1, use_multiprocessing=False, workers=num_workers\n",
    ")\n",
    "\n",
    "print(\"Untrained model's Test Evaluation:\")\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=test_gen,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    shuffle=False,\n",
    "    use_multiprocessing=False,\n",
    "    workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = model.evaluate(\n",
    "    test_gen, use_multiprocessing=False, workers=num_workers, verbose=1\n",
    ")\n",
    "\n",
    "print(\"Test Evaluation:\")\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = labels_test\n",
    "# Predict the rankings using the model:\n",
    "y_pred = model.predict(test_gen)\n",
    "# Mean baseline rankings = mean movie ranking:\n",
    "y_pred_baseline = np.full_like(y_pred, np.mean(y_true))\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred_baseline))\n",
    "mae = mean_absolute_error(y_true, y_pred_baseline)\n",
    "print(\"Mean Baseline Test set metrics:\")\n",
    "print(\"\\troot_mean_square_error = \", rmse)\n",
    "print(\"\\tmean_absolute_error = \", mae)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(\"\\nModel Test set metrics:\")\n",
    "print(\"\\troot_mean_square_error = \", rmse)\n",
    "print(\"\\tmean_absolute_error = \", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_true = plt.hist(y_true, bins=30, facecolor=\"green\", alpha=0.5)\n",
    "h_pred = plt.hist(y_pred, bins=30, facecolor=\"blue\", alpha=0.5)\n",
    "plt.xlabel(\"ranking\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.legend((\"True\", \"Predicted\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Metadata \"category\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Amz_Dataset()\n",
    "G, edges_with_ratings = dataset.load(metadata=True)\n",
    "\n",
    "\n",
    "from sklearn import model_selection\n",
    "edges_train, edges_test = model_selection.train_test_split(\n",
    "    edges_with_ratings, train_size=0.7, test_size=0.3\n",
    ")\n",
    "\n",
    "\n",
    "edgelist_train = list(edges_train[[\"user_id\", \"item_id\"]].itertuples(index=False))\n",
    "edgelist_test = list(edges_test[[\"user_id\", \"item_id\"]].itertuples(index=False))\n",
    "\n",
    "labels_train = edges_train[\"rating\"]\n",
    "labels_test = edges_test[\"rating\"]\n",
    "\n",
    "batch_size = 200\n",
    "epochs = 20\n",
    "\n",
    "num_samples = [8, 4]\n",
    "\n",
    "generator = HinSAGELinkGenerator(\n",
    "    G, batch_size, num_samples, head_node_types=[\"user\", \"item\"]\n",
    ")\n",
    "train_gen = generator.flow(edgelist_train, labels_train, shuffle=True)\n",
    "test_gen = generator.flow(edgelist_test, labels_test)\n",
    "generator.schema.type_adjacency_list(generator.head_node_types, len(num_samples))\n",
    "\n",
    "\n",
    "hinsage_layer_sizes = [32, 32]\n",
    "assert len(hinsage_layer_sizes) == len(num_samples)\n",
    "\n",
    "hinsage = HinSAGE(\n",
    "    layer_sizes=hinsage_layer_sizes, generator=generator, bias=True, dropout=0.0\n",
    ")\n",
    "\n",
    "\n",
    "# Expose input and output sockets of hinsage:\n",
    "x_inp, x_out = hinsage.in_out_tensors()\n",
    "\n",
    "\n",
    "# Final estimator layer\n",
    "score_prediction = link_regression(edge_embedding_method=\"concat\")(x_out)\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "def root_mean_square_error(s_true, s_pred):\n",
    "    return K.sqrt(K.mean(K.pow(s_true - s_pred, 2)))\n",
    "\n",
    "\n",
    "model = Model(inputs=x_inp, outputs=score_prediction)\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(lr=1e-2),\n",
    "    loss=losses.mean_squared_error,\n",
    "    metrics=[root_mean_square_error, metrics.mae],\n",
    ")\n",
    "\n",
    "# Specify the number of workers to use for model training\n",
    "num_workers = 4\n",
    "\n",
    "\n",
    "generator = HinSAGELinkGenerator(\n",
    "    G, batch_size, num_samples, head_node_types=[\"user\", \"item\"]\n",
    ")\n",
    "train_gen = generator.flow(edgelist_train, labels_train, shuffle=True)\n",
    "test_gen = generator.flow(edgelist_test, labels_test)\n",
    "\n",
    "from stellargraph.mapper import GraphSAGENodeGenerator, HinSAGENodeGenerator\n",
    "\n",
    "\n",
    "def get_embeddings(G, nodes):\n",
    "    x_inp_src = x_inp[0::2]\n",
    "    x_out_src = x_out[0]\n",
    "    embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)\n",
    "    node_ids = nodes\n",
    "    # egd = HinSAGENodeGenerator(G, batch_size, num_samples, head_node_types=[\"user\", \"item\"]).flow(node_ids)\n",
    "\n",
    "    node_embeddings = model.predict(test_gen, workers=4, verbose=1)\n",
    "\n",
    "    return node_embeddings\n",
    "\n",
    "\n",
    "new_embeddings = get_embeddings(G, G.nodes())\n",
    "\n",
    "\n",
    "test_metrics = model.evaluate(\n",
    "    test_gen, verbose=1, use_multiprocessing=False, workers=num_workers\n",
    ")\n",
    "\n",
    "print(\"Untrained model's Test Evaluation:\")\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=test_gen,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    shuffle=False,\n",
    "    use_multiprocessing=False,\n",
    "    workers=num_workers,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_metrics = model.evaluate(\n",
    "    test_gen, use_multiprocessing=False, workers=num_workers, verbose=1\n",
    ")\n",
    "\n",
    "print(\"Test Evaluation:\")\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))\n",
    "\n",
    "y_true = labels_test\n",
    "# Predict the rankings using the model:\n",
    "y_pred = model.predict(test_gen)\n",
    "# Mean baseline rankings = mean movie ranking:\n",
    "y_pred_baseline = np.full_like(y_pred, np.mean(y_true))\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred_baseline))\n",
    "mae = mean_absolute_error(y_true, y_pred_baseline)\n",
    "print(\"Mean Baseline Test set metrics:\")\n",
    "print(\"\\troot_mean_square_error = \", rmse)\n",
    "print(\"\\tmean_absolute_error = \", mae)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(\"\\nModel Test set metrics:\")\n",
    "print(\"\\troot_mean_square_error = \", rmse)\n",
    "print(\"\\tmean_absolute_error = \", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Amz_Dataset()\n",
    "G, edges_with_ratings = dataset.load(metadata=False)\n",
    "\n",
    "\n",
    "from sklearn import model_selection\n",
    "edges_train, edges_test = model_selection.train_test_split(\n",
    "    edges_with_ratings, train_size=0.7, test_size=0.3\n",
    ")\n",
    "\n",
    "\n",
    "edgelist_train = list(edges_train[[\"user_id\", \"item_id\"]].itertuples(index=False))\n",
    "edgelist_test = list(edges_test[[\"user_id\", \"item_id\"]].itertuples(index=False))\n",
    "\n",
    "labels_train = edges_train[\"rating\"]\n",
    "labels_test = edges_test[\"rating\"]\n",
    "\n",
    "batch_size = 200\n",
    "epochs = 20\n",
    "\n",
    "num_samples = [8, 4]\n",
    "\n",
    "generator = HinSAGELinkGenerator(\n",
    "    G, batch_size, num_samples, head_node_types=[\"user\", \"item\"]\n",
    ")\n",
    "train_gen = generator.flow(edgelist_train, labels_train, shuffle=True)\n",
    "test_gen = generator.flow(edgelist_test, labels_test)\n",
    "generator.schema.type_adjacency_list(generator.head_node_types, len(num_samples))\n",
    "\n",
    "\n",
    "hinsage_layer_sizes = [32, 32]\n",
    "assert len(hinsage_layer_sizes) == len(num_samples)\n",
    "\n",
    "hinsage = HinSAGE(\n",
    "    layer_sizes=hinsage_layer_sizes, generator=generator, bias=True, dropout=0.0\n",
    ")\n",
    "\n",
    "\n",
    "# Expose input and output sockets of hinsage:\n",
    "x_inp, x_out = hinsage.in_out_tensors()\n",
    "\n",
    "\n",
    "# Final estimator layer\n",
    "score_prediction = link_regression(edge_embedding_method=\"concat\")(x_out)\n",
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "def root_mean_square_error(s_true, s_pred):\n",
    "    return K.sqrt(K.mean(K.pow(s_true - s_pred, 2)))\n",
    "\n",
    "\n",
    "model = Model(inputs=x_inp, outputs=score_prediction)\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(lr=1e-2),\n",
    "    loss=losses.mean_squared_error,\n",
    "    metrics=[root_mean_square_error, metrics.mae],\n",
    ")\n",
    "\n",
    "# Specify the number of workers to use for model training\n",
    "num_workers = 4\n",
    "\n",
    "\n",
    "generator = HinSAGELinkGenerator(\n",
    "    G, batch_size, num_samples, head_node_types=[\"user\", \"item\"]\n",
    ")\n",
    "train_gen = generator.flow(edgelist_train, labels_train, shuffle=True)\n",
    "test_gen = generator.flow(edgelist_test, labels_test)\n",
    "\n",
    "from stellargraph.mapper import GraphSAGENodeGenerator, HinSAGENodeGenerator\n",
    "\n",
    "\n",
    "def get_embeddings(G, nodes):\n",
    "    x_inp_src = x_inp[0::2]\n",
    "    x_out_src = x_out[0]\n",
    "    embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)\n",
    "    node_ids = nodes\n",
    "    # egd = HinSAGENodeGenerator(G, batch_size, num_samples, head_node_types=[\"user\", \"item\"]).flow(node_ids)\n",
    "\n",
    "    node_embeddings = model.predict(test_gen, workers=4, verbose=1)\n",
    "\n",
    "    return node_embeddings\n",
    "\n",
    "\n",
    "new_embeddings = get_embeddings(G, G.nodes())\n",
    "\n",
    "\n",
    "test_metrics = model.evaluate(\n",
    "    test_gen, verbose=1, use_multiprocessing=False, workers=num_workers\n",
    ")\n",
    "\n",
    "print(\"Untrained model's Test Evaluation:\")\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=test_gen,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    shuffle=False,\n",
    "    use_multiprocessing=False,\n",
    "    workers=num_workers,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_metrics = model.evaluate(\n",
    "    test_gen, use_multiprocessing=False, workers=num_workers, verbose=1\n",
    ")\n",
    "\n",
    "print(\"Test Evaluation:\")\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))\n",
    "\n",
    "y_true = labels_test\n",
    "# Predict the rankings using the model:\n",
    "y_pred = model.predict(test_gen)\n",
    "# Mean baseline rankings = mean movie ranking:\n",
    "y_pred_baseline = np.full_like(y_pred, np.mean(y_true))\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred_baseline))\n",
    "mae = mean_absolute_error(y_true, y_pred_baseline)\n",
    "print(\"Mean Baseline Test set metrics:\")\n",
    "print(\"\\troot_mean_square_error = \", rmse)\n",
    "print(\"\\tmean_absolute_error = \", mae)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(\"\\nModel Test set metrics:\")\n",
    "print(\"\\troot_mean_square_error = \", rmse)\n",
    "print(\"\\tmean_absolute_error = \", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Normalization or laplacian of adjcency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.to_numpy_matrix(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_mode = A + np.eye(g.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_mode = np.zeros_like(A_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_mode.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(A_mode.sum(axis=1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(D_mode, np.asarray(A_mode.sum(axis=1)).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "from numpy.linalg import inv\n",
    "\n",
    "D_mod_inv_root = inv(sqrtm(D_mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpah_matrix = D_mod_inv_root @ A_mode @ D_mod_inv_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 0],\n",
    "              [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[5, 0],\n",
    "              [1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_mod_inv_root[].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpah_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isDiag(M):\n",
    "    i, j = np.nonzero(M)\n",
    "    return np.all(i == j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isDiag(D_mod_inv_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isDiag(A_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
